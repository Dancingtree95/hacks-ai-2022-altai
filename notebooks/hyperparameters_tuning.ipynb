{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\manic\\Desktop\\Алтай\\env\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from optuna.integration import CatBoostPruningCallback\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val_score_catboost(catboost_config, X, Y, cat_cols, pruning_callback, n_splits = 10, use_folds = 10, average = 'macro', seed = 42):\n",
    "    kf = StratifiedKFold(n_splits = n_splits, shuffle = True, random_state=seed)\n",
    "    scores = [] \n",
    "    for i,(tr_id, ts_id) in enumerate(kf.split(X, Y)):\n",
    "        model = CatBoostClassifier(**catboost_config)\n",
    "\n",
    "        X_tr, Y_tr = X.iloc[tr_id], Y.iloc[tr_id]\n",
    "        X_ts, Y_ts = X.iloc[ts_id], Y.iloc[ts_id]\n",
    "\n",
    "\n",
    "        tr_pool = Pool(X_tr, Y_tr, cat_features=cat_cols)\n",
    "        ts_pool = Pool(X_ts, Y_ts, cat_features=cat_cols)\n",
    "\n",
    "        model.fit(tr_pool, eval_set = ts_pool, verbose = False, callbacks=[pruning_callback])\n",
    "\n",
    "        pruning_callback.check_pruned()\n",
    "\n",
    "        pr_ts = np.squeeze(model.predict(ts_pool))\n",
    "\n",
    "        scores.append(f1_score(Y.iloc[ts_id], pr_ts, average=average))\n",
    "\n",
    "        if (i >= use_folds - 1):\n",
    "            break\n",
    "\n",
    "    return np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    data = pd.read_csv('processed_train.csv')\n",
    "    X, Y = data.drop(columns=['ID', 'Статус']), data['Статус']\n",
    "    with open('categorical_features.pickle', 'rb') as f:\n",
    "        cat_cols = pickle.load(f)\n",
    "    return X, Y, cat_cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def objective(trial: optuna.Trial, X, Y, cat_cols) -> float:\n",
    "\n",
    "\n",
    "    catboost_config = {\n",
    "        'use_best_model':True,\n",
    "        'early_stopping_rounds':300,\n",
    "        'eval_metric': 'TotalF1:average=Macro',\n",
    "        'random_seed' : 14121995, \n",
    "        'max_ctr_complexity' : 0,\n",
    "        'iterations' : 1500,\n",
    "        #'rsm' : trial.suggest_float('rsm', 0.1, 1, step = 0.1),\n",
    "        'rsm': 0.5,\n",
    "        #\"objective\": trial.suggest_categorical(\"objective\", [\"MultiClass\", \"MultiClassOneVsAll\"]),\n",
    "        \"depth\": trial.suggest_int(\"depth\", 3, 7),\n",
    "        #'l2_leaf_reg': trial.suggest_float(\"reg_lambda\", 0, 7), \n",
    "        'learning_rate': trial.suggest_float(\"learning_rate\", 0.01, 0.15)\n",
    "        #\"boosting_type\": trial.suggest_categorical(\"boosting_type\", [\"Ordered\", \"Plain\"]),\n",
    "        #\"bootstrap_type\": trial.suggest_categorical( \"bootstrap_type\", [\"Bayesian\", \"Bernoulli\"]),\n",
    "        \n",
    "    }\n",
    "    #if catboost_config[\"bootstrap_type\"] == \"Bayesian\":\n",
    "    #    catboost_config[\"bagging_temperature\"] = trial.suggest_float(\"bagging_temperature\", 0, 10)\n",
    "    #elif catboost_config[\"bootstrap_type\"] == \"Bernoulli\":\n",
    "    #    catboost_config[\"subsample\"] = trial.suggest_float(\"subsample\", 0.1, 1, log=True)\n",
    "\n",
    "\n",
    "    pruning_callback = CatBoostPruningCallback(trial, \"TotalF1:average=Macro\")\n",
    "    score = cross_val_score_catboost(catboost_config, X, Y, cat_cols, pruning_callback, use_folds = 5)\n",
    "\n",
    "\n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-17 03:11:22,369]\u001b[0m A new study created in memory with name: no-name-24b466e0-019d-4871-8aa8-2a26657d44b6\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:13:00,534]\u001b[0m Trial 0 finished with value: 0.7843979556551525 and parameters: {'depth': 6, 'learning_rate': 0.09641663725977909}. Best is trial 0 with value: 0.7843979556551525.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:15:48,691]\u001b[0m Trial 1 finished with value: 0.7925352014639795 and parameters: {'depth': 7, 'learning_rate': 0.13907458506242387}. Best is trial 1 with value: 0.7925352014639795.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:18:36,922]\u001b[0m Trial 2 finished with value: 0.7845759615683551 and parameters: {'depth': 6, 'learning_rate': 0.03830989456160043}. Best is trial 1 with value: 0.7925352014639795.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:20:18,077]\u001b[0m Trial 3 finished with value: 0.786569056250689 and parameters: {'depth': 4, 'learning_rate': 0.08074281932281033}. Best is trial 1 with value: 0.7925352014639795.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:23:04,525]\u001b[0m Trial 4 finished with value: 0.7932335666847344 and parameters: {'depth': 7, 'learning_rate': 0.125378077063454}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:25:16,360]\u001b[0m Trial 5 finished with value: 0.7825793706556039 and parameters: {'depth': 4, 'learning_rate': 0.04378694207513201}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:27:20,689]\u001b[0m Trial 6 finished with value: 0.7869146390229369 and parameters: {'depth': 5, 'learning_rate': 0.12725388463301393}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:28:46,000]\u001b[0m Trial 7 finished with value: 0.779982354182698 and parameters: {'depth': 4, 'learning_rate': 0.07897963712110813}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:30:47,757]\u001b[0m Trial 8 finished with value: 0.7861168430551417 and parameters: {'depth': 6, 'learning_rate': 0.0818498563239261}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:32:17,317]\u001b[0m Trial 9 finished with value: 0.7824821065255552 and parameters: {'depth': 3, 'learning_rate': 0.1366257754207475}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:35:09,873]\u001b[0m Trial 10 finished with value: 0.7902143973366667 and parameters: {'depth': 7, 'learning_rate': 0.11013818325524771}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:37:24,439]\u001b[0m Trial 11 finished with value: 0.7916029342374082 and parameters: {'depth': 7, 'learning_rate': 0.14675998913859623}. Best is trial 4 with value: 0.7932335666847344.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:39:40,760]\u001b[0m Trial 12 finished with value: 0.7999392590176997 and parameters: {'depth': 7, 'learning_rate': 0.1225565736872559}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:41:53,458]\u001b[0m Trial 13 finished with value: 0.7879589913749696 and parameters: {'depth': 7, 'learning_rate': 0.11341069438502227}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:45:24,630]\u001b[0m Trial 14 finished with value: 0.7757836473118256 and parameters: {'depth': 6, 'learning_rate': 0.012395601410392296}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:47:28,270]\u001b[0m Trial 15 finished with value: 0.7869872547753206 and parameters: {'depth': 5, 'learning_rate': 0.11514379871255269}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:50:10,144]\u001b[0m Trial 16 finished with value: 0.7949863183395212 and parameters: {'depth': 7, 'learning_rate': 0.09825101935710595}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:52:52,955]\u001b[0m Trial 17 finished with value: 0.7852852307514246 and parameters: {'depth': 6, 'learning_rate': 0.0600130510054089}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:55:06,074]\u001b[0m Trial 18 finished with value: 0.791959941149486 and parameters: {'depth': 5, 'learning_rate': 0.09827540743733068}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:57:37,415]\u001b[0m Trial 19 finished with value: 0.7928152339942433 and parameters: {'depth': 7, 'learning_rate': 0.09333419256202985}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:57:39,199]\u001b[0m Trial 20 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 03:59:51,721]\u001b[0m Trial 21 finished with value: 0.788272356536407 and parameters: {'depth': 7, 'learning_rate': 0.1260490998827079}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:02:13,823]\u001b[0m Trial 22 finished with value: 0.7862451284263502 and parameters: {'depth': 7, 'learning_rate': 0.12442564506788893}. Best is trial 12 with value: 0.7999392590176997.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:02:16,109]\u001b[0m Trial 23 pruned. Trial was pruned at iteration 63.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:05:12,165]\u001b[0m Trial 24 finished with value: 0.8008979900717141 and parameters: {'depth': 7, 'learning_rate': 0.12149644728550123}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:05:14,417]\u001b[0m Trial 25 pruned. Trial was pruned at iteration 56.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:07:36,001]\u001b[0m Trial 26 finished with value: 0.7915523440527596 and parameters: {'depth': 7, 'learning_rate': 0.10405326133612655}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:07:37,157]\u001b[0m Trial 27 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:07:39,452]\u001b[0m Trial 28 pruned. Trial was pruned at iteration 63.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:07:42,258]\u001b[0m Trial 29 pruned. Trial was pruned at iteration 74.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:07:44,797]\u001b[0m Trial 30 pruned. Trial was pruned at iteration 60.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:10:05,600]\u001b[0m Trial 31 finished with value: 0.791507538559083 and parameters: {'depth': 7, 'learning_rate': 0.1198957459525448}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:10:15,536]\u001b[0m Trial 32 pruned. Trial was pruned at iteration 222.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:12:44,549]\u001b[0m Trial 33 finished with value: 0.7940330838155238 and parameters: {'depth': 7, 'learning_rate': 0.1032410102941943}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:14:53,115]\u001b[0m Trial 34 finished with value: 0.789064292216622 and parameters: {'depth': 7, 'learning_rate': 0.10215117459778664}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:14:55,195]\u001b[0m Trial 35 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:14:57,589]\u001b[0m Trial 36 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:17:34,477]\u001b[0m Trial 37 finished with value: 0.7907407309489923 and parameters: {'depth': 7, 'learning_rate': 0.11058381909137588}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:17:36,534]\u001b[0m Trial 38 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:20:11,733]\u001b[0m Trial 39 finished with value: 0.7991879104345835 and parameters: {'depth': 7, 'learning_rate': 0.1412893953728623}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:20:13,292]\u001b[0m Trial 40 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:22:38,923]\u001b[0m Trial 41 finished with value: 0.7942370664958653 and parameters: {'depth': 7, 'learning_rate': 0.12871108045441307}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:25:02,941]\u001b[0m Trial 42 finished with value: 0.7912183319817324 and parameters: {'depth': 7, 'learning_rate': 0.14146066406952007}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:27:11,978]\u001b[0m Trial 43 finished with value: 0.7913879651316755 and parameters: {'depth': 7, 'learning_rate': 0.1304700788709187}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:29:40,412]\u001b[0m Trial 44 finished with value: 0.7956334674232235 and parameters: {'depth': 7, 'learning_rate': 0.12302862968911674}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:29:42,641]\u001b[0m Trial 45 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:31:33,978]\u001b[0m Trial 46 finished with value: 0.7960035250561568 and parameters: {'depth': 7, 'learning_rate': 0.1436791541415017}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:33:26,583]\u001b[0m Trial 47 finished with value: 0.7856277546695158 and parameters: {'depth': 7, 'learning_rate': 0.14938745780084933}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:33:29,311]\u001b[0m Trial 48 pruned. Trial was pruned at iteration 68.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:35:59,115]\u001b[0m Trial 49 finished with value: 0.7918048081439703 and parameters: {'depth': 7, 'learning_rate': 0.1362921958260155}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:36:01,058]\u001b[0m Trial 50 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:38:18,295]\u001b[0m Trial 51 finished with value: 0.7900383081000845 and parameters: {'depth': 7, 'learning_rate': 0.11599538263540922}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:38:23,026]\u001b[0m Trial 52 pruned. Trial was pruned at iteration 106.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:40:54,875]\u001b[0m Trial 53 finished with value: 0.7886511805512587 and parameters: {'depth': 7, 'learning_rate': 0.12457880225271091}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:42:49,231]\u001b[0m Trial 54 finished with value: 0.7888917123567565 and parameters: {'depth': 7, 'learning_rate': 0.1306795897980715}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:42:51,711]\u001b[0m Trial 55 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:42:53,458]\u001b[0m Trial 56 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:42:56,007]\u001b[0m Trial 57 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:44:47,172]\u001b[0m Trial 58 finished with value: 0.7955478077043174 and parameters: {'depth': 7, 'learning_rate': 0.13726764793080345}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:44:48,421]\u001b[0m Trial 59 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:44:50,778]\u001b[0m Trial 60 pruned. Trial was pruned at iteration 55.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:44:53,603]\u001b[0m Trial 61 pruned. Trial was pruned at iteration 63.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:44:56,028]\u001b[0m Trial 62 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:44:58,248]\u001b[0m Trial 63 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:44:59,551]\u001b[0m Trial 64 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:45:01,438]\u001b[0m Trial 65 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:47:11,316]\u001b[0m Trial 66 finished with value: 0.7893412251528249 and parameters: {'depth': 7, 'learning_rate': 0.13808732642886654}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:47:13,896]\u001b[0m Trial 67 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:47:16,327]\u001b[0m Trial 68 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:47:18,820]\u001b[0m Trial 69 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:47:21,296]\u001b[0m Trial 70 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:47:24,433]\u001b[0m Trial 71 pruned. Trial was pruned at iteration 67.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:47:26,781]\u001b[0m Trial 72 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:49:59,806]\u001b[0m Trial 73 finished with value: 0.7987235400845957 and parameters: {'depth': 7, 'learning_rate': 0.14472341454765628}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:52:27,642]\u001b[0m Trial 74 finished with value: 0.7946344662915391 and parameters: {'depth': 7, 'learning_rate': 0.1432915892328465}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:52:32,350]\u001b[0m Trial 75 pruned. Trial was pruned at iteration 105.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:52:35,204]\u001b[0m Trial 76 pruned. Trial was pruned at iteration 59.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:54:58,968]\u001b[0m Trial 77 finished with value: 0.7991186780543763 and parameters: {'depth': 7, 'learning_rate': 0.12309368946776202}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:55:01,517]\u001b[0m Trial 78 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:55:03,813]\u001b[0m Trial 79 pruned. Trial was pruned at iteration 55.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:57:01,399]\u001b[0m Trial 80 finished with value: 0.7868304563781051 and parameters: {'depth': 7, 'learning_rate': 0.12191886240892523}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:57:04,078]\u001b[0m Trial 81 pruned. Trial was pruned at iteration 56.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:57:06,749]\u001b[0m Trial 82 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:57:09,227]\u001b[0m Trial 83 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:57:14,253]\u001b[0m Trial 84 pruned. Trial was pruned at iteration 105.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:57:16,525]\u001b[0m Trial 85 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:59:10,751]\u001b[0m Trial 86 finished with value: 0.7869628131535864 and parameters: {'depth': 7, 'learning_rate': 0.13055565709643652}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 04:59:13,210]\u001b[0m Trial 87 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:01:04,451]\u001b[0m Trial 88 finished with value: 0.7899895818666602 and parameters: {'depth': 7, 'learning_rate': 0.13598167345010442}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:01:06,661]\u001b[0m Trial 89 pruned. Trial was pruned at iteration 55.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:01:09,112]\u001b[0m Trial 90 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:01:11,649]\u001b[0m Trial 91 pruned. Trial was pruned at iteration 55.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:01:15,671]\u001b[0m Trial 92 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:03:06,395]\u001b[0m Trial 93 finished with value: 0.7898491720615748 and parameters: {'depth': 7, 'learning_rate': 0.13172501934871317}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:03:08,861]\u001b[0m Trial 94 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:03:11,327]\u001b[0m Trial 95 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:03:13,711]\u001b[0m Trial 96 pruned. Trial was pruned at iteration 75.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:05:31,404]\u001b[0m Trial 97 finished with value: 0.797558204393362 and parameters: {'depth': 7, 'learning_rate': 0.14345260749305042}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:07:37,010]\u001b[0m Trial 98 finished with value: 0.7975649057361522 and parameters: {'depth': 7, 'learning_rate': 0.12251143128124553}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:09:46,451]\u001b[0m Trial 99 finished with value: 0.8002392579727646 and parameters: {'depth': 7, 'learning_rate': 0.12261365588935338}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:11:46,927]\u001b[0m Trial 100 finished with value: 0.7867989889127315 and parameters: {'depth': 7, 'learning_rate': 0.12214502520996898}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:24,216]\u001b[0m Trial 101 finished with value: 0.7898902697289227 and parameters: {'depth': 7, 'learning_rate': 0.12454356596356639}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:27,609]\u001b[0m Trial 102 pruned. Trial was pruned at iteration 79.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:30,018]\u001b[0m Trial 103 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:32,574]\u001b[0m Trial 104 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:35,479]\u001b[0m Trial 105 pruned. Trial was pruned at iteration 63.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:37,770]\u001b[0m Trial 106 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:40,171]\u001b[0m Trial 107 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:41,682]\u001b[0m Trial 108 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:14:43,845]\u001b[0m Trial 109 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:16:56,388]\u001b[0m Trial 110 finished with value: 0.7896480085937189 and parameters: {'depth': 7, 'learning_rate': 0.12134912793822862}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:16:58,748]\u001b[0m Trial 111 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:19:03,307]\u001b[0m Trial 112 finished with value: 0.7938954514088832 and parameters: {'depth': 7, 'learning_rate': 0.14402819190635946}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:19,512]\u001b[0m Trial 113 finished with value: 0.7905069329249941 and parameters: {'depth': 7, 'learning_rate': 0.13013307527390577}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:23,715]\u001b[0m Trial 114 pruned. Trial was pruned at iteration 85.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:26,208]\u001b[0m Trial 115 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:28,785]\u001b[0m Trial 116 pruned. Trial was pruned at iteration 56.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:31,408]\u001b[0m Trial 117 pruned. Trial was pruned at iteration 58.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:33,783]\u001b[0m Trial 118 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:37,310]\u001b[0m Trial 119 pruned. Trial was pruned at iteration 75.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:39,857]\u001b[0m Trial 120 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:21:42,958]\u001b[0m Trial 121 pruned. Trial was pruned at iteration 63.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:24:06,724]\u001b[0m Trial 122 finished with value: 0.7931365891492956 and parameters: {'depth': 7, 'learning_rate': 0.14426140637133153}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:24:16,162]\u001b[0m Trial 123 pruned. Trial was pruned at iteration 215.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:26:11,428]\u001b[0m Trial 124 finished with value: 0.7910095701051258 and parameters: {'depth': 7, 'learning_rate': 0.138532781000926}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:26:15,413]\u001b[0m Trial 125 pruned. Trial was pruned at iteration 85.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:26:17,776]\u001b[0m Trial 126 pruned. Trial was pruned at iteration 58.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:26:20,339]\u001b[0m Trial 127 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:26:22,862]\u001b[0m Trial 128 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:26:24,713]\u001b[0m Trial 129 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:28:24,849]\u001b[0m Trial 130 finished with value: 0.797527733664038 and parameters: {'depth': 7, 'learning_rate': 0.1351623125015908}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:28:55,188]\u001b[0m Trial 131 pruned. Trial was pruned at iteration 357.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:30:34,812]\u001b[0m Trial 132 finished with value: 0.7894339589877327 and parameters: {'depth': 7, 'learning_rate': 0.14035854378574955}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:32:32,463]\u001b[0m Trial 133 finished with value: 0.7891648286694789 and parameters: {'depth': 7, 'learning_rate': 0.1202760102737523}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:32:34,780]\u001b[0m Trial 134 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:34:42,252]\u001b[0m Trial 135 finished with value: 0.7907924918246223 and parameters: {'depth': 7, 'learning_rate': 0.13049374921683307}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:34:45,152]\u001b[0m Trial 136 pruned. Trial was pruned at iteration 58.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:36:55,246]\u001b[0m Trial 137 finished with value: 0.7913729762393005 and parameters: {'depth': 7, 'learning_rate': 0.1447891429080723}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:36:56,774]\u001b[0m Trial 138 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:36:59,342]\u001b[0m Trial 139 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:37:01,667]\u001b[0m Trial 140 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:37:04,118]\u001b[0m Trial 141 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:37:06,987]\u001b[0m Trial 142 pruned. Trial was pruned at iteration 65.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:37:08,062]\u001b[0m Trial 143 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:37:17,091]\u001b[0m Trial 144 pruned. Trial was pruned at iteration 214.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:37:19,589]\u001b[0m Trial 145 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:39:44,718]\u001b[0m Trial 146 finished with value: 0.7886310985531313 and parameters: {'depth': 7, 'learning_rate': 0.12502526999943814}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:39:47,052]\u001b[0m Trial 147 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:39:50,011]\u001b[0m Trial 148 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:39:52,130]\u001b[0m Trial 149 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:39:55,730]\u001b[0m Trial 150 pruned. Trial was pruned at iteration 79.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:39:57,978]\u001b[0m Trial 151 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:06,869]\u001b[0m Trial 152 finished with value: 0.7917060858918447 and parameters: {'depth': 7, 'learning_rate': 0.12226211985120702}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:09,292]\u001b[0m Trial 153 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:12,018]\u001b[0m Trial 154 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:14,490]\u001b[0m Trial 155 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:16,886]\u001b[0m Trial 156 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:19,319]\u001b[0m Trial 157 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:21,511]\u001b[0m Trial 158 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:42:24,609]\u001b[0m Trial 159 pruned. Trial was pruned at iteration 65.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:28,213]\u001b[0m Trial 160 finished with value: 0.7909337238965031 and parameters: {'depth': 7, 'learning_rate': 0.1367000964529852}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:30,821]\u001b[0m Trial 161 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:33,502]\u001b[0m Trial 162 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:35,792]\u001b[0m Trial 163 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:38,712]\u001b[0m Trial 164 pruned. Trial was pruned at iteration 64.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:41,540]\u001b[0m Trial 165 pruned. Trial was pruned at iteration 63.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:43,682]\u001b[0m Trial 166 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:45,856]\u001b[0m Trial 167 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:55,437]\u001b[0m Trial 168 pruned. Trial was pruned at iteration 214.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:44:57,668]\u001b[0m Trial 169 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:48:11,745]\u001b[0m Trial 170 finished with value: 0.795618167745243 and parameters: {'depth': 7, 'learning_rate': 0.1385735744193812}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:48:16,769]\u001b[0m Trial 171 pruned. Trial was pruned at iteration 73.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:48:20,081]\u001b[0m Trial 172 pruned. Trial was pruned at iteration 52.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:48:24,044]\u001b[0m Trial 173 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:51:15,656]\u001b[0m Trial 174 finished with value: 0.7905019045816131 and parameters: {'depth': 7, 'learning_rate': 0.13775798432912556}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:51:18,869]\u001b[0m Trial 175 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:53:52,903]\u001b[0m Trial 176 finished with value: 0.7912622483427083 and parameters: {'depth': 7, 'learning_rate': 0.14306611666393354}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:53:56,538]\u001b[0m Trial 177 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:53:58,709]\u001b[0m Trial 178 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:57:30,137]\u001b[0m Trial 179 finished with value: 0.7867574283330244 and parameters: {'depth': 7, 'learning_rate': 0.12100193621677048}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:57:33,660]\u001b[0m Trial 180 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:57:37,166]\u001b[0m Trial 181 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:57:40,669]\u001b[0m Trial 182 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:57:54,052]\u001b[0m Trial 183 pruned. Trial was pruned at iteration 214.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 05:57:57,706]\u001b[0m Trial 184 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:01:03,071]\u001b[0m Trial 185 finished with value: 0.8002392579727646 and parameters: {'depth': 7, 'learning_rate': 0.12262637175170653}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:01:06,760]\u001b[0m Trial 186 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:01:10,254]\u001b[0m Trial 187 pruned. Trial was pruned at iteration 52.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:01:15,420]\u001b[0m Trial 188 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:04:17,403]\u001b[0m Trial 189 finished with value: 0.7937433491162718 and parameters: {'depth': 7, 'learning_rate': 0.12132689293859192}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:04:20,904]\u001b[0m Trial 190 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:07:36,897]\u001b[0m Trial 191 finished with value: 0.7876812640752457 and parameters: {'depth': 7, 'learning_rate': 0.12101423684429392}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:07:40,238]\u001b[0m Trial 192 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:07:44,344]\u001b[0m Trial 193 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:07:48,239]\u001b[0m Trial 194 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:07:51,639]\u001b[0m Trial 195 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:07:55,722]\u001b[0m Trial 196 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:07:59,175]\u001b[0m Trial 197 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:10:34,835]\u001b[0m Trial 198 finished with value: 0.791360768972137 and parameters: {'depth': 7, 'learning_rate': 0.12184363886585316}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:10:38,081]\u001b[0m Trial 199 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:13:35,172]\u001b[0m Trial 200 finished with value: 0.7947734706631815 and parameters: {'depth': 7, 'learning_rate': 0.13599489252655572}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:16:40,251]\u001b[0m Trial 201 finished with value: 0.791716089286036 and parameters: {'depth': 7, 'learning_rate': 0.135886071144808}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:16:45,569]\u001b[0m Trial 202 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:16:50,531]\u001b[0m Trial 203 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:16:57,710]\u001b[0m Trial 204 pruned. Trial was pruned at iteration 107.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:19:45,880]\u001b[0m Trial 205 finished with value: 0.7954966354972108 and parameters: {'depth': 7, 'learning_rate': 0.13723114265512906}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:22:22,605]\u001b[0m Trial 206 finished with value: 0.7896658324705563 and parameters: {'depth': 7, 'learning_rate': 0.1363985936231994}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:22:26,088]\u001b[0m Trial 207 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:22:30,081]\u001b[0m Trial 208 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:26:32,274]\u001b[0m Trial 209 finished with value: 0.7924334355910538 and parameters: {'depth': 7, 'learning_rate': 0.13834607060529572}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:29:14,638]\u001b[0m Trial 210 finished with value: 0.790515028983434 and parameters: {'depth': 7, 'learning_rate': 0.1430866932218512}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:29:18,148]\u001b[0m Trial 211 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:29:21,801]\u001b[0m Trial 212 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:29:25,258]\u001b[0m Trial 213 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:29:30,500]\u001b[0m Trial 214 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:29:34,150]\u001b[0m Trial 215 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:29:37,542]\u001b[0m Trial 216 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:32:25,349]\u001b[0m Trial 217 finished with value: 0.7912162543271718 and parameters: {'depth': 7, 'learning_rate': 0.12121013264146943}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:35:02,420]\u001b[0m Trial 218 finished with value: 0.7914515576423182 and parameters: {'depth': 7, 'learning_rate': 0.1358075141129874}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:35:05,790]\u001b[0m Trial 219 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:39:45,494]\u001b[0m Trial 220 finished with value: 0.7964585081056975 and parameters: {'depth': 7, 'learning_rate': 0.13040027453109823}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:39:48,917]\u001b[0m Trial 221 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:39:52,308]\u001b[0m Trial 222 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:39:55,997]\u001b[0m Trial 223 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:42:51,297]\u001b[0m Trial 224 finished with value: 0.7910339352300474 and parameters: {'depth': 7, 'learning_rate': 0.13801281562882345}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:46:06,506]\u001b[0m Trial 225 finished with value: 0.7940529227141488 and parameters: {'depth': 7, 'learning_rate': 0.1411220429690775}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:46:11,874]\u001b[0m Trial 226 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:49:29,221]\u001b[0m Trial 227 finished with value: 0.7946528648360167 and parameters: {'depth': 7, 'learning_rate': 0.1411272286304638}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:49:34,202]\u001b[0m Trial 228 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:52:37,183]\u001b[0m Trial 229 finished with value: 0.7942934680561677 and parameters: {'depth': 7, 'learning_rate': 0.13562442705049726}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:55:47,414]\u001b[0m Trial 230 finished with value: 0.7959179850068729 and parameters: {'depth': 7, 'learning_rate': 0.136212628780585}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:58:52,426]\u001b[0m Trial 231 finished with value: 0.7966465117262225 and parameters: {'depth': 7, 'learning_rate': 0.13600164568185527}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 06:58:58,503]\u001b[0m Trial 232 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:02:11,098]\u001b[0m Trial 233 finished with value: 0.7933135642605647 and parameters: {'depth': 7, 'learning_rate': 0.13686705436553517}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:02:14,569]\u001b[0m Trial 234 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:02:18,750]\u001b[0m Trial 235 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:05:59,085]\u001b[0m Trial 236 finished with value: 0.7918048081439703 and parameters: {'depth': 7, 'learning_rate': 0.1362874554003692}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:06:01,750]\u001b[0m Trial 237 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:06:05,168]\u001b[0m Trial 238 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:06:08,677]\u001b[0m Trial 239 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:06:12,489]\u001b[0m Trial 240 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:09:36,889]\u001b[0m Trial 241 finished with value: 0.8000423881533347 and parameters: {'depth': 7, 'learning_rate': 0.14134262571599968}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:13:03,834]\u001b[0m Trial 242 finished with value: 0.7919580976853045 and parameters: {'depth': 7, 'learning_rate': 0.14102641307966246}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:13:07,533]\u001b[0m Trial 243 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:13:10,888]\u001b[0m Trial 244 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:13:16,650]\u001b[0m Trial 245 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:13:22,766]\u001b[0m Trial 246 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:16:56,643]\u001b[0m Trial 247 finished with value: 0.7953880339410363 and parameters: {'depth': 7, 'learning_rate': 0.14396782653579515}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:16:59,991]\u001b[0m Trial 248 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:17:04,390]\u001b[0m Trial 249 pruned. Trial was pruned at iteration 65.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:17:09,137]\u001b[0m Trial 250 pruned. Trial was pruned at iteration 66.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:17:12,383]\u001b[0m Trial 251 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:17:17,668]\u001b[0m Trial 252 pruned. Trial was pruned at iteration 73.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:21:20,300]\u001b[0m Trial 253 finished with value: 0.7978422191001466 and parameters: {'depth': 7, 'learning_rate': 0.13554725713744029}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:21:26,202]\u001b[0m Trial 254 pruned. Trial was pruned at iteration 85.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:21:32,217]\u001b[0m Trial 255 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:21:35,514]\u001b[0m Trial 256 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:21:38,857]\u001b[0m Trial 257 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:24:34,143]\u001b[0m Trial 258 finished with value: 0.7959831718871634 and parameters: {'depth': 7, 'learning_rate': 0.14315775464995428}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:24:37,619]\u001b[0m Trial 259 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:24:40,967]\u001b[0m Trial 260 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:24:44,585]\u001b[0m Trial 261 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:27:23,044]\u001b[0m Trial 262 finished with value: 0.7896658324705563 and parameters: {'depth': 7, 'learning_rate': 0.13638946832916338}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:27:27,672]\u001b[0m Trial 263 pruned. Trial was pruned at iteration 65.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:27:31,127]\u001b[0m Trial 264 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:30:58,166]\u001b[0m Trial 265 finished with value: 0.7949546250342482 and parameters: {'depth': 7, 'learning_rate': 0.13855581652858118}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:34:25,773]\u001b[0m Trial 266 finished with value: 0.7919046767868579 and parameters: {'depth': 7, 'learning_rate': 0.136859150105235}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:34:28,968]\u001b[0m Trial 267 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:34:32,542]\u001b[0m Trial 268 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:34:36,424]\u001b[0m Trial 269 pruned. Trial was pruned at iteration 57.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:34:42,163]\u001b[0m Trial 270 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:38:56,663]\u001b[0m Trial 271 finished with value: 0.7935110281364441 and parameters: {'depth': 7, 'learning_rate': 0.1306115682605686}. Best is trial 24 with value: 0.8008979900717141.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:39:00,172]\u001b[0m Trial 272 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:39:01,794]\u001b[0m Trial 273 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:39:05,334]\u001b[0m Trial 274 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:42:48,584]\u001b[0m Trial 275 finished with value: 0.8017112782638989 and parameters: {'depth': 7, 'learning_rate': 0.13504974389679972}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:42:52,030]\u001b[0m Trial 276 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:42:59,078]\u001b[0m Trial 277 pruned. Trial was pruned at iteration 107.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:43:01,076]\u001b[0m Trial 278 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:43:04,566]\u001b[0m Trial 279 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:43:13,129]\u001b[0m Trial 280 pruned. Trial was pruned at iteration 137.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:43:16,510]\u001b[0m Trial 281 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:43:19,937]\u001b[0m Trial 282 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:46:45,002]\u001b[0m Trial 283 finished with value: 0.8015870966860777 and parameters: {'depth': 7, 'learning_rate': 0.1350489977825369}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:46:48,763]\u001b[0m Trial 284 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:46:52,479]\u001b[0m Trial 285 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:46:55,761]\u001b[0m Trial 286 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:46:58,958]\u001b[0m Trial 287 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:47:02,539]\u001b[0m Trial 288 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:47:08,161]\u001b[0m Trial 289 pruned. Trial was pruned at iteration 85.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:47:11,840]\u001b[0m Trial 290 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:47:15,365]\u001b[0m Trial 291 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:50:48,220]\u001b[0m Trial 292 finished with value: 0.7889749491339646 and parameters: {'depth': 7, 'learning_rate': 0.11555307357996702}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:54:25,749]\u001b[0m Trial 293 finished with value: 0.7913613061632343 and parameters: {'depth': 7, 'learning_rate': 0.13648946593096847}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:54:29,329]\u001b[0m Trial 294 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:54:32,896]\u001b[0m Trial 295 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:54:36,574]\u001b[0m Trial 296 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:57:17,029]\u001b[0m Trial 297 finished with value: 0.7970319805950591 and parameters: {'depth': 7, 'learning_rate': 0.13617157709152297}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 07:57:19,415]\u001b[0m Trial 298 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:00:17,696]\u001b[0m Trial 299 finished with value: 0.7910339352300474 and parameters: {'depth': 7, 'learning_rate': 0.13802646628562296}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:00:21,110]\u001b[0m Trial 300 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:00:25,732]\u001b[0m Trial 301 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:00:41,263]\u001b[0m Trial 302 pruned. Trial was pruned at iteration 252.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:04:08,910]\u001b[0m Trial 303 finished with value: 0.7947899432032106 and parameters: {'depth': 7, 'learning_rate': 0.141120795715756}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:04:12,298]\u001b[0m Trial 304 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:04:16,523]\u001b[0m Trial 305 pruned. Trial was pruned at iteration 64.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:04:19,849]\u001b[0m Trial 306 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:04:23,331]\u001b[0m Trial 307 pruned. Trial was pruned at iteration 51.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:04:26,888]\u001b[0m Trial 308 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:07:28,860]\u001b[0m Trial 309 finished with value: 0.7958497086363269 and parameters: {'depth': 7, 'learning_rate': 0.13536282322966534}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:07:32,486]\u001b[0m Trial 310 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:07:35,476]\u001b[0m Trial 311 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:07:38,928]\u001b[0m Trial 312 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:07:57,967]\u001b[0m Trial 313 pruned. Trial was pruned at iteration 289.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:08:01,551]\u001b[0m Trial 314 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:08:05,140]\u001b[0m Trial 315 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:08:08,938]\u001b[0m Trial 316 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:08:12,323]\u001b[0m Trial 317 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:08:16,061]\u001b[0m Trial 318 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:08:19,386]\u001b[0m Trial 319 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:08:22,636]\u001b[0m Trial 320 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:11:17,576]\u001b[0m Trial 321 finished with value: 0.7969526674397195 and parameters: {'depth': 7, 'learning_rate': 0.1351313788846115}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:11:21,174]\u001b[0m Trial 322 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:11:24,648]\u001b[0m Trial 323 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:13:55,206]\u001b[0m Trial 324 finished with value: 0.7948903674296822 and parameters: {'depth': 7, 'learning_rate': 0.12285466618217693}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:13:58,919]\u001b[0m Trial 325 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:14:02,437]\u001b[0m Trial 326 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:16:46,464]\u001b[0m Trial 327 finished with value: 0.790982518884046 and parameters: {'depth': 7, 'learning_rate': 0.13541307401813116}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:16:50,127]\u001b[0m Trial 328 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:16:53,692]\u001b[0m Trial 329 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:16:57,300]\u001b[0m Trial 330 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:17:02,546]\u001b[0m Trial 331 pruned. Trial was pruned at iteration 87.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:22,368]\u001b[0m Trial 332 finished with value: 0.7981947184453951 and parameters: {'depth': 7, 'learning_rate': 0.14122872252125981}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:26,505]\u001b[0m Trial 333 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:30,130]\u001b[0m Trial 334 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:34,580]\u001b[0m Trial 335 pruned. Trial was pruned at iteration 68.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:37,890]\u001b[0m Trial 336 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:43,537]\u001b[0m Trial 337 pruned. Trial was pruned at iteration 85.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:46,772]\u001b[0m Trial 338 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:20:50,172]\u001b[0m Trial 339 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:24:52,830]\u001b[0m Trial 340 finished with value: 0.7980659677783548 and parameters: {'depth': 7, 'learning_rate': 0.13552645067720756}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:24:56,359]\u001b[0m Trial 341 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:25:00,290]\u001b[0m Trial 342 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:27:57,566]\u001b[0m Trial 343 finished with value: 0.797527733664038 and parameters: {'depth': 7, 'learning_rate': 0.1351662546433044}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:00,944]\u001b[0m Trial 344 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:04,121]\u001b[0m Trial 345 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:06,493]\u001b[0m Trial 346 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:10,052]\u001b[0m Trial 347 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:13,906]\u001b[0m Trial 348 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:32,188]\u001b[0m Trial 349 pruned. Trial was pruned at iteration 287.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:35,617]\u001b[0m Trial 350 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:28:40,382]\u001b[0m Trial 351 pruned. Trial was pruned at iteration 73.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:31:46,034]\u001b[0m Trial 352 finished with value: 0.7942934680561677 and parameters: {'depth': 7, 'learning_rate': 0.1356173256594443}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:31:49,484]\u001b[0m Trial 353 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:29,026]\u001b[0m Trial 354 finished with value: 0.7937274156448488 and parameters: {'depth': 7, 'learning_rate': 0.14416613975045842}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:32,451]\u001b[0m Trial 355 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:35,788]\u001b[0m Trial 356 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:39,052]\u001b[0m Trial 357 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:42,419]\u001b[0m Trial 358 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:45,708]\u001b[0m Trial 359 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:48,938]\u001b[0m Trial 360 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:35:51,071]\u001b[0m Trial 361 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:38:47,483]\u001b[0m Trial 362 finished with value: 0.7940602602885877 and parameters: {'depth': 7, 'learning_rate': 0.13730487031983588}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:38:51,232]\u001b[0m Trial 363 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:38:54,649]\u001b[0m Trial 364 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:38:57,945]\u001b[0m Trial 365 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:42:53,713]\u001b[0m Trial 366 finished with value: 0.7979623665238974 and parameters: {'depth': 7, 'learning_rate': 0.14470883920031244}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:42:57,130]\u001b[0m Trial 367 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:02,086]\u001b[0m Trial 368 pruned. Trial was pruned at iteration 81.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:05,375]\u001b[0m Trial 369 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:08,693]\u001b[0m Trial 370 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:11,979]\u001b[0m Trial 371 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:15,562]\u001b[0m Trial 372 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:19,281]\u001b[0m Trial 373 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:22,561]\u001b[0m Trial 374 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:43:27,443]\u001b[0m Trial 375 pruned. Trial was pruned at iteration 73.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:46:03,815]\u001b[0m Trial 376 finished with value: 0.7909585022332685 and parameters: {'depth': 7, 'learning_rate': 0.1430296944820901}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:46:07,248]\u001b[0m Trial 377 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:46:10,956]\u001b[0m Trial 378 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:46:14,547]\u001b[0m Trial 379 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:46:17,982]\u001b[0m Trial 380 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:46:19,963]\u001b[0m Trial 381 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:46:23,363]\u001b[0m Trial 382 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:49:25,945]\u001b[0m Trial 383 finished with value: 0.7957828084974916 and parameters: {'depth': 7, 'learning_rate': 0.12051316403341109}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:49:29,339]\u001b[0m Trial 384 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:49:32,476]\u001b[0m Trial 385 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:49:35,961]\u001b[0m Trial 386 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:52:31,212]\u001b[0m Trial 387 finished with value: 0.7955776623399459 and parameters: {'depth': 7, 'learning_rate': 0.13493912509379705}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:52:34,957]\u001b[0m Trial 388 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:52:38,127]\u001b[0m Trial 389 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:52:40,144]\u001b[0m Trial 390 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:55:49,806]\u001b[0m Trial 391 finished with value: 0.7918942485006175 and parameters: {'depth': 7, 'learning_rate': 0.13647251070912944}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:55:53,463]\u001b[0m Trial 392 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:55:56,682]\u001b[0m Trial 393 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:56:00,205]\u001b[0m Trial 394 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:56:03,579]\u001b[0m Trial 395 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:56:08,403]\u001b[0m Trial 396 pruned. Trial was pruned at iteration 72.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:56:12,207]\u001b[0m Trial 397 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:56:15,738]\u001b[0m Trial 398 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 08:56:20,290]\u001b[0m Trial 399 pruned. Trial was pruned at iteration 73.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:00:37,044]\u001b[0m Trial 400 finished with value: 0.7943530585268698 and parameters: {'depth': 7, 'learning_rate': 0.13060681543939479}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:00:40,324]\u001b[0m Trial 401 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:00:43,749]\u001b[0m Trial 402 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:00:47,231]\u001b[0m Trial 403 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:00:52,176]\u001b[0m Trial 404 pruned. Trial was pruned at iteration 81.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:00:55,716]\u001b[0m Trial 405 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:00:59,538]\u001b[0m Trial 406 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:01:01,908]\u001b[0m Trial 407 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:01:05,196]\u001b[0m Trial 408 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:01:08,736]\u001b[0m Trial 409 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:01:11,805]\u001b[0m Trial 410 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:01:15,330]\u001b[0m Trial 411 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:01:18,783]\u001b[0m Trial 412 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:03:52,725]\u001b[0m Trial 413 finished with value: 0.7909585022332685 and parameters: {'depth': 7, 'learning_rate': 0.14303464002191354}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:03:56,406]\u001b[0m Trial 414 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:04:15,386]\u001b[0m Trial 415 pruned. Trial was pruned at iteration 287.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:04:18,749]\u001b[0m Trial 416 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:04:22,109]\u001b[0m Trial 417 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:04:25,655]\u001b[0m Trial 418 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:07:42,306]\u001b[0m Trial 419 finished with value: 0.7911793800934684 and parameters: {'depth': 7, 'learning_rate': 0.14478586026121804}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:07:45,931]\u001b[0m Trial 420 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:07:49,573]\u001b[0m Trial 421 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:07:53,424]\u001b[0m Trial 422 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:07:56,629]\u001b[0m Trial 423 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:00,493]\u001b[0m Trial 424 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:04,221]\u001b[0m Trial 425 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:07,793]\u001b[0m Trial 426 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:11,332]\u001b[0m Trial 427 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:14,837]\u001b[0m Trial 428 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:18,058]\u001b[0m Trial 429 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:21,489]\u001b[0m Trial 430 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:25,150]\u001b[0m Trial 431 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:28,354]\u001b[0m Trial 432 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:32,769]\u001b[0m Trial 433 pruned. Trial was pruned at iteration 63.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:36,197]\u001b[0m Trial 434 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:08:39,674]\u001b[0m Trial 435 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:11:44,637]\u001b[0m Trial 436 finished with value: 0.7937433491162718 and parameters: {'depth': 7, 'learning_rate': 0.12132421623022281}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:11:50,019]\u001b[0m Trial 437 pruned. Trial was pruned at iteration 81.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:11:53,451]\u001b[0m Trial 438 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:11:56,953]\u001b[0m Trial 439 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:12:00,504]\u001b[0m Trial 440 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:12:04,041]\u001b[0m Trial 441 pruned. Trial was pruned at iteration 53.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:12:06,899]\u001b[0m Trial 442 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:12:10,601]\u001b[0m Trial 443 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:12:14,024]\u001b[0m Trial 444 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:15:55,252]\u001b[0m Trial 445 finished with value: 0.8005649022026098 and parameters: {'depth': 7, 'learning_rate': 0.13534124832635358}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:15:58,472]\u001b[0m Trial 446 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:16:01,630]\u001b[0m Trial 447 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:16:10,993]\u001b[0m Trial 448 pruned. Trial was pruned at iteration 151.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:16:14,207]\u001b[0m Trial 449 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:16:17,856]\u001b[0m Trial 450 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:19:14,733]\u001b[0m Trial 451 finished with value: 0.7913387074108063 and parameters: {'depth': 7, 'learning_rate': 0.14419282340220393}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:19:18,072]\u001b[0m Trial 452 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:05,418]\u001b[0m Trial 453 finished with value: 0.7955738786018165 and parameters: {'depth': 7, 'learning_rate': 0.13707078148103724}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:08,749]\u001b[0m Trial 454 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:12,465]\u001b[0m Trial 455 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:39,405]\u001b[0m Trial 456 pruned. Trial was pruned at iteration 425.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:42,624]\u001b[0m Trial 457 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:46,012]\u001b[0m Trial 458 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:49,434]\u001b[0m Trial 459 pruned. Trial was pruned at iteration 52.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:52,718]\u001b[0m Trial 460 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:22:56,209]\u001b[0m Trial 461 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:25:32,490]\u001b[0m Trial 462 finished with value: 0.7896658324705563 and parameters: {'depth': 7, 'learning_rate': 0.1364107139733379}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:25:35,921]\u001b[0m Trial 463 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:25:39,373]\u001b[0m Trial 464 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:25:42,969]\u001b[0m Trial 465 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:25:45,775]\u001b[0m Trial 466 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:25:49,063]\u001b[0m Trial 467 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:26:16,177]\u001b[0m Trial 468 pruned. Trial was pruned at iteration 425.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:26:19,708]\u001b[0m Trial 469 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:26:23,094]\u001b[0m Trial 470 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:26:27,386]\u001b[0m Trial 471 pruned. Trial was pruned at iteration 64.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:26:30,779]\u001b[0m Trial 472 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:29:38,482]\u001b[0m Trial 473 finished with value: 0.7907924918246223 and parameters: {'depth': 7, 'learning_rate': 0.13050940154608287}. Best is trial 275 with value: 0.8017112782638989.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:29:40,762]\u001b[0m Trial 474 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:29:43,962]\u001b[0m Trial 475 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:05,689]\u001b[0m Trial 476 pruned. Trial was pruned at iteration 351.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:08,925]\u001b[0m Trial 477 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:12,347]\u001b[0m Trial 478 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:15,816]\u001b[0m Trial 479 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:19,717]\u001b[0m Trial 480 pruned. Trial was pruned at iteration 64.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:22,761]\u001b[0m Trial 481 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:24,889]\u001b[0m Trial 482 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:28,164]\u001b[0m Trial 483 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:31,588]\u001b[0m Trial 484 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:34,901]\u001b[0m Trial 485 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:38,585]\u001b[0m Trial 486 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:43,364]\u001b[0m Trial 487 pruned. Trial was pruned at iteration 73.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:46,676]\u001b[0m Trial 488 pruned. Trial was pruned at iteration 54.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:50,133]\u001b[0m Trial 489 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:53,173]\u001b[0m Trial 490 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:30:56,527]\u001b[0m Trial 491 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:31:00,058]\u001b[0m Trial 492 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:31:03,622]\u001b[0m Trial 493 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:31:07,002]\u001b[0m Trial 494 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:31:10,161]\u001b[0m Trial 495 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:31:13,823]\u001b[0m Trial 496 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:31:17,236]\u001b[0m Trial 497 pruned. Trial was pruned at iteration 50.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:32:37,603]\u001b[0m Trial 498 pruned. Trial was pruned at iteration 496.\u001b[0m\n",
      "\u001b[32m[I 2022-09-17 09:32:41,104]\u001b[0m Trial 499 pruned. Trial was pruned at iteration 50.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_startup_trials = 20, n_warmup_steps=50), direction=\"maximize\")\n",
    "study.optimize(lambda trial : objective(trial, *load_data()), n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'depth': 7, 'learning_rate': 0.13504974389679972}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = study.trials_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = experiments.loc[experiments['state'] != 'PRUNED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['value', 'params_depth',  'params_learning_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>params_depth</th>\n",
       "      <th>params_learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.789666</td>\n",
       "      <td>7</td>\n",
       "      <td>0.136399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.789648</td>\n",
       "      <td>7</td>\n",
       "      <td>0.121349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.789434</td>\n",
       "      <td>7</td>\n",
       "      <td>0.140359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.789341</td>\n",
       "      <td>7</td>\n",
       "      <td>0.138087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.789165</td>\n",
       "      <td>7</td>\n",
       "      <td>0.120276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.789064</td>\n",
       "      <td>7</td>\n",
       "      <td>0.102151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>0.788975</td>\n",
       "      <td>7</td>\n",
       "      <td>0.115553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.788892</td>\n",
       "      <td>7</td>\n",
       "      <td>0.130680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.788651</td>\n",
       "      <td>7</td>\n",
       "      <td>0.124579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.788631</td>\n",
       "      <td>7</td>\n",
       "      <td>0.125025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.788272</td>\n",
       "      <td>7</td>\n",
       "      <td>0.126049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.787959</td>\n",
       "      <td>7</td>\n",
       "      <td>0.113411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0.787681</td>\n",
       "      <td>7</td>\n",
       "      <td>0.121014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.786987</td>\n",
       "      <td>5</td>\n",
       "      <td>0.115144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.786963</td>\n",
       "      <td>7</td>\n",
       "      <td>0.130556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.786915</td>\n",
       "      <td>5</td>\n",
       "      <td>0.127254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.786830</td>\n",
       "      <td>7</td>\n",
       "      <td>0.121919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.786799</td>\n",
       "      <td>7</td>\n",
       "      <td>0.122145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0.786757</td>\n",
       "      <td>7</td>\n",
       "      <td>0.121002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.786569</td>\n",
       "      <td>4</td>\n",
       "      <td>0.080743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.786245</td>\n",
       "      <td>7</td>\n",
       "      <td>0.124426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.786117</td>\n",
       "      <td>6</td>\n",
       "      <td>0.081850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.785628</td>\n",
       "      <td>7</td>\n",
       "      <td>0.149387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.785285</td>\n",
       "      <td>6</td>\n",
       "      <td>0.060013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.784576</td>\n",
       "      <td>6</td>\n",
       "      <td>0.038310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.784398</td>\n",
       "      <td>6</td>\n",
       "      <td>0.096417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.782579</td>\n",
       "      <td>4</td>\n",
       "      <td>0.043787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.782482</td>\n",
       "      <td>3</td>\n",
       "      <td>0.136626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.779982</td>\n",
       "      <td>4</td>\n",
       "      <td>0.078980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.775784</td>\n",
       "      <td>6</td>\n",
       "      <td>0.012396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        value  params_depth  params_learning_rate\n",
       "206  0.789666             7              0.136399\n",
       "110  0.789648             7              0.121349\n",
       "132  0.789434             7              0.140359\n",
       "66   0.789341             7              0.138087\n",
       "133  0.789165             7              0.120276\n",
       "34   0.789064             7              0.102151\n",
       "292  0.788975             7              0.115553\n",
       "54   0.788892             7              0.130680\n",
       "53   0.788651             7              0.124579\n",
       "146  0.788631             7              0.125025\n",
       "21   0.788272             7              0.126049\n",
       "13   0.787959             7              0.113411\n",
       "191  0.787681             7              0.121014\n",
       "15   0.786987             5              0.115144\n",
       "86   0.786963             7              0.130556\n",
       "6    0.786915             5              0.127254\n",
       "80   0.786830             7              0.121919\n",
       "100  0.786799             7              0.122145\n",
       "179  0.786757             7              0.121002\n",
       "3    0.786569             4              0.080743\n",
       "22   0.786245             7              0.124426\n",
       "8    0.786117             6              0.081850\n",
       "47   0.785628             7              0.149387\n",
       "17   0.785285             6              0.060013\n",
       "2    0.784576             6              0.038310\n",
       "0    0.784398             6              0.096417\n",
       "5    0.782579             4              0.043787\n",
       "9    0.782482             3              0.136626\n",
       "7    0.779982             4              0.078980\n",
       "14   0.775784             6              0.012396"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiments[cols].sort_values('value', ascending = False).iloc[-30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'iterations': 500,\n",
       " 'rsm': 0.4,\n",
       " 'depth': 7,\n",
       " 'reg_lambda': 25.3399242267677,\n",
       " 'boosting_type': 'Ordered',\n",
       " 'bootstrap_type': 'Bernoulli',\n",
       " 'subsample': 0.7178700936638458}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3f492cb1abf92620539c60030079aacb93e34dff8b698949905a09c2556ac080"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
